// Test configuration for PYPROPHET_PARQUET_FULL subworkflow
// Tests the full scoring and inference pipeline on Parquet OSWPQD format

params {
  pyprophet {
    peakgroup_scoring {
      classifier      = "LDA"
      level           = "ms2"
      threads         = 2
      ss_num_iter     = 3
      ss_initial_fdr  = 0.15
      ss_iteration_fdr = 0.05
      ss_main_score    = 'var_xcorr_shape'
      xeval_num_iter   = 3
    }

    transition_scoring {
      classifier      = "LDA"
      level           = "transition"
      threads         = 2
      ss_num_iter     = 3
      ss_initial_fdr  = 0.15
      ss_iteration_fdr = 0.05
      ss_main_score    = 'var_xcorr_shape'
      xeval_num_iter   = 3
      ipf_max_peakgroup_rank  = 1
      ipf_max_peakgroup_pep = 0.7
      ipf_max_transition_isotope_overlap = 0.5
      ipf_min_transition_sn = -1
    }
  }

  pyprophet_export_tsv {
    max_rs_peakgroup_qvalue = 0.05
    max_global_peptide_qvalue = 0.01
    max_global_protein_qvalue = 0.01
  }
}

process {
  // Export parquet process - generate test data with split_runs
  withName: 'PYPROPHET_EXPORT_PARQUET' {
    cpus = 2
    memory = '4.GB'
    time = '30.m'
    ext.args = '--split_runs'
    containerOptions = '--env HOME=/tmp --env MPLCONFIGDIR=/tmp/matplotlib --env DUCKDB_HOME=/tmp/duckdb'
  }

  // PyProphet subworkflow processes
  withName: 'PYPROPHET_PARQUET_FULL:.*' {
    cpus = 2
    memory = '4.GB'
    time = '1.h'
    containerOptions = '--env HOME=/tmp --env MPLCONFIGDIR=/tmp/matplotlib --env DUCKDB_HOME=/tmp/duckdb'
  }
}

profiles {
  docker {
    docker.enabled = true
    docker.runOptions = '-u $(id -u):$(id -g) --env HOME=/tmp --env MPLCONFIGDIR=/tmp/matplotlib --env DUCKDB_HOME=/tmp/duckdb'
    singularity.enabled = false
  }
  
  singularity {
    singularity.enabled = true
    singularity.autoMounts = true
    docker.enabled = false
  }
}
